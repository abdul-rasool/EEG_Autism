{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, RepeatVector, TimeDistributed, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import os\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "ukdDgEGyl-k-"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MI33WFHeknCp",
        "outputId": "b5d01cd7-cee5-499d-ecc6-8d23fbbc8690"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Mounting Google Drive\"\"\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "laNwjnxadwgx"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_noise(df, noise_level=0.0001):\n",
        "    noisy_df = df.copy()\n",
        "    for column in df.select_dtypes(include=[np.number]).columns:\n",
        "        noise = np.random.normal(0, noise_level * df[column].std(), df[column].shape)\n",
        "        noisy_df[column] += noise\n",
        "    return noisy_df"
      ],
      "metadata": {
        "id": "6Pd1JUkkdxwT"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = \"/content/drive/MyDrive/Features ASD_TD/\"\n",
        "\n",
        "# Initialize an empty list to store the combined data and labels\n",
        "data_list = []\n",
        "labels = []\n",
        "# Iterate through the ASD and TD folders\n",
        "for label, folder_name in enumerate([\"ASD\", \"TD\"]):\n",
        "    folder_dir = os.path.join(folder_path, folder_name)\n",
        "\n",
        "    # Iterate through files in each folder\n",
        "    for file_name in os.listdir(folder_dir):\n",
        "        if file_name.endswith(\".xlsx\"):\n",
        "            file_path = os.path.join(folder_dir, file_name)\n",
        "            # Check if the corresponding bands file exists\n",
        "            bands_file_path = os.path.join(folder_dir, file_name.split('.')[0] + \"_bands.xlsx\")\n",
        "            if os.path.exists(bands_file_path):\n",
        "                # Read both excel files\n",
        "                df_main = pd.read_excel(file_path)\n",
        "                df_bands = pd.read_excel(bands_file_path)\n",
        "                # Combine along columns\n",
        "                combined_df = pd.concat([df_main, df_bands], axis=1)\n",
        "                combined_df = add_noise(combined_df)\n",
        "                # Append the combined data and label to the list\n",
        "                data_list.append(combined_df)\n",
        "                labels.append(label)"
      ],
      "metadata": {
        "id": "XjcEXWYLd0Xs"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# folder_path = \"/content/drive/MyDrive/Features ASD_TD/\"\n",
        "\n",
        "# data_list = []\n",
        "# labels = []\n",
        "# # Iterate through the ASD and TD folders\n",
        "# for label, folder_name in enumerate([\"ASD\", \"TD\"]):\n",
        "#     folder_dir = os.path.join(folder_path, folder_name)\n",
        "\n",
        "#     # Iterate through files in each folder\n",
        "#     for file_name in os.listdir(folder_dir):\n",
        "#         if file_name.endswith(\".xlsx\"):\n",
        "#             file_path = os.path.join(folder_dir, file_name)\n",
        "#             # Check if the corresponding bands file exists\n",
        "#             bands_file_path = os.path.join(folder_dir, file_name.split('.')[0] + \"_bands.xlsx\")\n",
        "#             if os.path.exists(bands_file_path):\n",
        "#                 # Read both excel files\n",
        "#                 df_main = pd.read_excel(file_path)\n",
        "#                 df_bands = pd.read_excel(bands_file_path)\n",
        "#                 # Combine along columns\n",
        "#                 combined_df = pd.concat([df_main, df_bands], axis=1)\n",
        "#                 # Append the combined data and label to the list\n",
        "#                 data_list.append(combined_df)\n",
        "#                 labels.append(label)"
      ],
      "metadata": {
        "id": "sHwbG06kl1xE"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = np.array(labels)"
      ],
      "metadata": {
        "id": "x5X2HL7lcpRN"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_list = np.array(data_list)"
      ],
      "metadata": {
        "id": "wImmC8wmgEVz"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "data_2d = np.asarray(data_list).reshape(-1, np.asarray(data_list).shape[-1])\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaled_data_2d = scaler.fit_transform(data_2d)\n",
        "data = scaled_data_2d.reshape(np.asarray(data_list).shape)"
      ],
      "metadata": {
        "id": "kmFAVLdHnZ4A"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Data Augmentation\"\"\"\n",
        "\n",
        "def augment_data(data, labels, target_samples=1000, noise_factor=0.5):\n",
        "    augmented_data = []\n",
        "    augmented_labels = []\n",
        "\n",
        "    while len(augmented_data) < target_samples:\n",
        "        idx = np.random.randint(0, len(data))\n",
        "        original_sample = data[idx]\n",
        "        original_label = labels[idx]\n",
        "\n",
        "        noisy_sample = original_sample + noise_factor * np.random.normal(size=original_sample.shape)\n",
        "\n",
        "        augmented_data.append(noisy_sample)\n",
        "        augmented_labels.append(original_label)\n",
        "\n",
        "    augmented_data = np.array(augmented_data)\n",
        "    augmented_labels = np.array(augmented_labels)\n",
        "\n",
        "    return augmented_data, augmented_labels\n",
        "\n",
        "augmented_data, augmented_labels = augment_data(data, labels, target_samples=1000, noise_factor=5)"
      ],
      "metadata": {
        "id": "1x9ccLGFou7K"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def AutoEncoder(n_features):\n",
        "\n",
        "    timesteps = 100\n",
        "    # n_features = 11\n",
        "    encoding_dim = 10  # Adjust encoding dimensions as needed\n",
        "\n",
        "    inputs = Input(shape=(timesteps, n_features))\n",
        "\n",
        "    # Encoder\n",
        "    encoded = LSTM(128, return_sequences=True)(inputs)\n",
        "    encoded = Dropout(0.2)(encoded)\n",
        "    encoded = LSTM(64, return_sequences=True)(encoded)\n",
        "    encoded = Dropout(0.2)(encoded)\n",
        "    encoded = LSTM(encoding_dim)(encoded)\n",
        "\n",
        "    # Decoder\n",
        "    decoded = RepeatVector(timesteps)(encoded)\n",
        "    decoded = LSTM(encoding_dim, return_sequences=True)(decoded)\n",
        "    decoded = Dropout(0.2)(decoded)\n",
        "    decoded = LSTM(64, return_sequences=True)(decoded)\n",
        "    decoded = Dropout(0.2)(decoded)\n",
        "    decoded = LSTM(128, return_sequences=True)(decoded)\n",
        "    decoded = TimeDistributed(Dense(n_features))(decoded)\n",
        "\n",
        "    autoencoder = Model(inputs, decoded)\n",
        "    encoder = Model(inputs, encoded)\n",
        "\n",
        "    autoencoder.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "    # Callbacks\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
        "\n",
        "\n",
        "    xgb_regressor = XGBRegressor(n_estimators=200, max_depth=3, learning_rate=0.0001)\n",
        "\n",
        "    linear_regressor = LinearRegression()\n",
        "\n",
        "    return autoencoder, encoder, xgb_regressor, linear_regressor"
      ],
      "metadata": {
        "id": "FKE7SX_OpN_e"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "accuracies = []\n",
        "all_y_true = []\n",
        "all_y_pred = []\n",
        "\n",
        "# Perform K-Fold CV\n",
        "for train_index, test_index in kf.split(data):\n",
        "    X_train, X_test = data[train_index], data[test_index]\n",
        "    y_train, y_test = labels[train_index], labels[test_index]\n",
        "\n",
        "    # Apply data augmentation\n",
        "    # X_train_aug, y_train_aug = augment_data(X_train, y_train, target_samples=1000, noise_factor=0.00005)\n",
        "    # X_test, y_test = augment_data(X_test, y_test, target_samples=1000, noise_factor=0.00005)\n",
        "\n",
        "    X_train_aug = X_train\n",
        "    X_test_aug = X_test\n",
        "    y_train_aug = y_train\n",
        "    y_test_aug = y_test\n",
        "\n",
        "    autoencoder, encoder, xgb_regressor, linear_regressor = AutoEncoder(11)\n",
        "\n",
        "    history = autoencoder.fit(X_train_aug, X_train_aug,\n",
        "                              epochs=50,\n",
        "                              batch_size=16,\n",
        "                              validation_split=0.1)\n",
        "\n",
        "    # Encode the training and test data\n",
        "    X_train_encoded = encoder.predict(X_train_aug)\n",
        "    X_test_encoded = encoder.predict(X_test)\n",
        "\n",
        "    xgb_regressor.fit(X_train_encoded, y_train_aug)\n",
        "\n",
        "    # Predict using XGBoost regressor\n",
        "    xgb_train_predictions = xgb_regressor.predict(X_train_encoded)\n",
        "    xgb_test_predictions = xgb_regressor.predict(X_test_encoded)\n",
        "\n",
        "    linear_regressor.fit(xgb_train_predictions.reshape(-1, 1), y_train_aug)\n",
        "\n",
        "    # Predict using Linear Regression model\n",
        "    final_train_predictions = linear_regressor.predict(xgb_train_predictions.reshape(-1, 1))\n",
        "    final_test_predictions = linear_regressor.predict(xgb_test_predictions.reshape(-1, 1))\n",
        "\n",
        "    threshold = 0.5\n",
        "    final_test_predictions_class = (final_test_predictions > threshold).astype(int)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = accuracy_score(y_test, final_test_predictions_class)\n",
        "    print(f'Final Model Accuracy: {accuracy:.2f}')\n",
        "\n",
        "    accuracies.append(accuracy)\n",
        "    all_y_true.extend(y_test)\n",
        "    all_y_pred.extend(final_test_predictions_class)\n",
        "    print(accuracies)\n",
        "\n",
        "mean_accuracy = np.mean(accuracies)\n",
        "\n",
        "\n",
        "conf_matrix = confusion_matrix(all_y_true, all_y_pred)\n",
        "conf_matrix_df = pd.DataFrame(conf_matrix, index=['TD', 'ASD'], columns=['TD', 'ASD'])\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.set_context('paper', font_scale=2.2)\n",
        "sns.heatmap(conf_matrix_df, annot=True, cmap='YlGnBu', fmt='g',\n",
        "            xticklabels=['ASD', 'TD'],\n",
        "            yticklabels=['ASD', 'TD'],\n",
        "            cbar=False)  # Remove the color bar\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.tight_layout()\n",
        "plt.savefig('conf_XGB.eps', format='eps')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MoAI4H7fUp_h",
        "outputId": "3c29f489-8404-4675-b33d-5221e0ed1e31"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - loss: 1.0013 - val_loss: 0.9921\n",
            "Epoch 2/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.9987 - val_loss: 0.9898\n",
            "Epoch 3/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.9965 - val_loss: 0.9862\n",
            "Epoch 4/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.9926 - val_loss: 0.9789\n",
            "Epoch 5/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.9858 - val_loss: 0.9665\n",
            "Epoch 6/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.9719 - val_loss: 0.9476\n",
            "Epoch 7/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.9548 - val_loss: 0.9713\n",
            "Epoch 8/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.9696 - val_loss: 0.9171\n",
            "Epoch 9/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.9310 - val_loss: 0.8994\n",
            "Epoch 10/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.9092 - val_loss: 0.8759\n",
            "Epoch 11/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.8823 - val_loss: 0.8601\n",
            "Epoch 12/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.8709 - val_loss: 0.8483\n",
            "Epoch 13/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.8581 - val_loss: 0.8241\n",
            "Epoch 14/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.8351 - val_loss: 0.8246\n",
            "Epoch 15/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.8295 - val_loss: 0.8095\n",
            "Epoch 16/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.8197 - val_loss: 0.8035\n",
            "Epoch 17/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.8096 - val_loss: 0.7946\n",
            "Epoch 18/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.8014 - val_loss: 0.7876\n",
            "Epoch 19/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.7960 - val_loss: 0.7780\n",
            "Epoch 20/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.7878 - val_loss: 0.7756\n",
            "Epoch 21/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.7832 - val_loss: 0.7689\n",
            "Epoch 22/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.7777 - val_loss: 0.7638\n",
            "Epoch 23/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.7704 - val_loss: 0.7585\n",
            "Epoch 24/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.7680 - val_loss: 0.7450\n",
            "Epoch 25/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.7555 - val_loss: 0.7445\n",
            "Epoch 26/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.7543 - val_loss: 0.7332\n",
            "Epoch 27/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.7425 - val_loss: 0.7336\n",
            "Epoch 28/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.7411 - val_loss: 0.7223\n",
            "Epoch 29/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.7366 - val_loss: 0.7207\n",
            "Epoch 30/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.7339 - val_loss: 0.7171\n",
            "Epoch 31/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.7248 - val_loss: 0.7060\n",
            "Epoch 32/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.7145 - val_loss: 0.7078\n",
            "Epoch 33/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.7158 - val_loss: 0.7066\n",
            "Epoch 34/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.7106 - val_loss: 0.6936\n",
            "Epoch 35/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.7099 - val_loss: 0.7160\n",
            "Epoch 36/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.7190 - val_loss: 0.6942\n",
            "Epoch 37/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.7036 - val_loss: 0.6970\n",
            "Epoch 38/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.7058 - val_loss: 0.6904\n",
            "Epoch 39/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.7011 - val_loss: 0.6812\n",
            "Epoch 40/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.6981 - val_loss: 0.6815\n",
            "Epoch 41/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.6970 - val_loss: 0.7101\n",
            "Epoch 42/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.7179 - val_loss: 0.7156\n",
            "Epoch 43/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.7229 - val_loss: 0.7008\n",
            "Epoch 44/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.7091 - val_loss: 0.6785\n",
            "Epoch 45/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.6901 - val_loss: 0.6765\n",
            "Epoch 46/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6851 - val_loss: 0.6687\n",
            "Epoch 47/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.6800 - val_loss: 0.6686\n",
            "Epoch 48/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.6822 - val_loss: 0.6664\n",
            "Epoch 49/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.6779 - val_loss: 0.6621\n",
            "Epoch 50/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.6732 - val_loss: 0.6602\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step\n",
            "Final Model Accuracy: 0.83\n",
            "[0.8333333333333334]\n",
            "Epoch 1/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - loss: 1.0008 - val_loss: 0.9927\n",
            "Epoch 2/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.9988 - val_loss: 0.9909\n",
            "Epoch 3/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.9963 - val_loss: 0.9872\n",
            "Epoch 4/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.9934 - val_loss: 0.9797\n",
            "Epoch 5/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.9855 - val_loss: 0.9641\n",
            "Epoch 6/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.9696 - val_loss: 0.9471\n",
            "Epoch 7/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.9515 - val_loss: 0.9181\n",
            "Epoch 8/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.9255 - val_loss: 0.8870\n",
            "Epoch 9/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.8932 - val_loss: 0.8731\n",
            "Epoch 10/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.8795 - val_loss: 0.8546\n",
            "Epoch 11/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.8633 - val_loss: 0.8234\n",
            "Epoch 12/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.8317 - val_loss: 0.8192\n",
            "Epoch 13/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.8268 - val_loss: 0.8085\n",
            "Epoch 14/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.8194 - val_loss: 0.7991\n",
            "Epoch 15/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.8070 - val_loss: 0.7944\n",
            "Epoch 16/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.8031 - val_loss: 0.7855\n",
            "Epoch 17/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.7943 - val_loss: 0.7847\n",
            "Epoch 18/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.7921 - val_loss: 0.7821\n",
            "Epoch 19/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.7916 - val_loss: 0.7843\n",
            "Epoch 20/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.7891 - val_loss: 0.7820\n",
            "Epoch 21/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.7886 - val_loss: 0.7752\n",
            "Epoch 22/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.7808 - val_loss: 0.7636\n",
            "Epoch 23/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.7711 - val_loss: 0.7522\n",
            "Epoch 24/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.7625 - val_loss: 0.7572\n",
            "Epoch 25/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.7676 - val_loss: 0.7423\n",
            "Epoch 26/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.7502 - val_loss: 0.7351\n",
            "Epoch 27/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.7442 - val_loss: 0.7323\n",
            "Epoch 28/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7415 - val_loss: 0.7264\n",
            "Epoch 29/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.7353 - val_loss: 0.7257\n",
            "Epoch 30/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.7382 - val_loss: 0.7334\n",
            "Epoch 31/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.7380 - val_loss: 0.7218\n",
            "Epoch 32/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.7329 - val_loss: 0.7137\n",
            "Epoch 33/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.7222 - val_loss: 0.7085\n",
            "Epoch 34/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.7170 - val_loss: 0.7049\n",
            "Epoch 35/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7170 - val_loss: 0.7171\n",
            "Epoch 36/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.7216 - val_loss: 0.7073\n",
            "Epoch 37/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.7148 - val_loss: 0.7024\n",
            "Epoch 38/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.7114 - val_loss: 0.6966\n",
            "Epoch 39/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.7114 - val_loss: 0.6974\n",
            "Epoch 40/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.7071 - val_loss: 0.6901\n",
            "Epoch 41/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.6988 - val_loss: 0.6920\n",
            "Epoch 42/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.7002 - val_loss: 0.6851\n",
            "Epoch 43/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.6925 - val_loss: 0.6824\n",
            "Epoch 44/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.6920 - val_loss: 0.6812\n",
            "Epoch 45/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.6905 - val_loss: 0.6975\n",
            "Epoch 46/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.7051 - val_loss: 0.6860\n",
            "Epoch 47/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.6998 - val_loss: 0.6776\n",
            "Epoch 48/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.6903 - val_loss: 0.6759\n",
            "Epoch 49/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.6862 - val_loss: 0.6787\n",
            "Epoch 50/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.6890 - val_loss: 0.7334\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step\n",
            "Final Model Accuracy: 0.83\n",
            "[0.8333333333333334, 0.8333333333333334]\n",
            "Epoch 1/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - loss: 0.9988 - val_loss: 0.9925\n",
            "Epoch 2/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.9964 - val_loss: 0.9903\n",
            "Epoch 3/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.9944 - val_loss: 0.9866\n",
            "Epoch 4/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.9903 - val_loss: 0.9782\n",
            "Epoch 5/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.9810 - val_loss: 0.9591\n",
            "Epoch 6/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.9618 - val_loss: 0.9258\n",
            "Epoch 7/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.9367 - val_loss: 0.8977\n",
            "Epoch 8/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.9054 - val_loss: 0.8776\n",
            "Epoch 9/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.8840 - val_loss: 0.8639\n",
            "Epoch 10/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.8711 - val_loss: 0.8445\n",
            "Epoch 11/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.8495 - val_loss: 0.8278\n",
            "Epoch 12/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.8308 - val_loss: 0.8136\n",
            "Epoch 13/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.8230 - val_loss: 0.8039\n",
            "Epoch 14/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.8095 - val_loss: 0.8032\n",
            "Epoch 15/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.8097 - val_loss: 0.7967\n",
            "Epoch 16/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.8016 - val_loss: 0.7989\n",
            "Epoch 17/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.8039 - val_loss: 0.7886\n",
            "Epoch 18/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.7953 - val_loss: 0.7821\n",
            "Epoch 19/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.7902 - val_loss: 0.7713\n",
            "Epoch 20/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.7775 - val_loss: 0.7714\n",
            "Epoch 21/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.7760 - val_loss: 0.7712\n",
            "Epoch 22/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.7774 - val_loss: 0.7941\n",
            "Epoch 23/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.7974 - val_loss: 0.7943\n",
            "Epoch 24/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.7954 - val_loss: 0.8010\n",
            "Epoch 25/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.8055 - val_loss: 0.7517\n",
            "Epoch 26/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.7639 - val_loss: 0.7601\n",
            "Epoch 27/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.7657 - val_loss: 0.7570\n",
            "Epoch 28/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.7595 - val_loss: 0.7410\n",
            "Epoch 29/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.7497 - val_loss: 0.7289\n",
            "Epoch 30/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.7381 - val_loss: 0.7275\n",
            "Epoch 31/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.7364 - val_loss: 0.7218\n",
            "Epoch 32/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7283 - val_loss: 0.7180\n",
            "Epoch 33/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.7229 - val_loss: 0.7151\n",
            "Epoch 34/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.7215 - val_loss: 0.7154\n",
            "Epoch 35/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.7202 - val_loss: 0.7208\n",
            "Epoch 36/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.7288 - val_loss: 0.7113\n",
            "Epoch 37/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.7151 - val_loss: 0.7166\n",
            "Epoch 38/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.7250 - val_loss: 0.7082\n",
            "Epoch 39/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.7140 - val_loss: 0.7030\n",
            "Epoch 40/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.7131 - val_loss: 0.6921\n",
            "Epoch 41/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.6989 - val_loss: 0.6917\n",
            "Epoch 42/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.6984 - val_loss: 0.6892\n",
            "Epoch 43/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.6948 - val_loss: 0.6921\n",
            "Epoch 44/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.6949 - val_loss: 0.6891\n",
            "Epoch 45/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.6951 - val_loss: 0.6865\n",
            "Epoch 46/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.6932 - val_loss: 0.6821\n",
            "Epoch 47/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.6899 - val_loss: 0.6783\n",
            "Epoch 48/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6851 - val_loss: 0.6776\n",
            "Epoch 49/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.6868 - val_loss: 0.6745\n",
            "Epoch 50/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.6831 - val_loss: 0.6715\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step\n",
            "Final Model Accuracy: 1.00\n",
            "[0.8333333333333334, 0.8333333333333334, 1.0]\n",
            "Epoch 1/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - loss: 1.0010 - val_loss: 0.9935\n",
            "Epoch 2/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 1.0002 - val_loss: 0.9919\n",
            "Epoch 3/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.9977 - val_loss: 0.9898\n",
            "Epoch 4/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.9962 - val_loss: 0.9862\n",
            "Epoch 5/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.9925 - val_loss: 0.9794\n",
            "Epoch 6/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.9857 - val_loss: 0.9662\n",
            "Epoch 7/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.9738 - val_loss: 0.9492\n",
            "Epoch 8/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.9572 - val_loss: 0.9324\n",
            "Epoch 9/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.9374 - val_loss: 0.8924\n",
            "Epoch 10/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.9024 - val_loss: 0.8711\n",
            "Epoch 11/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.8790 - val_loss: 0.8474\n",
            "Epoch 12/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.8597 - val_loss: 0.8275\n",
            "Epoch 13/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.8389 - val_loss: 0.8203\n",
            "Epoch 14/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.8293 - val_loss: 0.8063\n",
            "Epoch 15/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.8162 - val_loss: 0.8077\n",
            "Epoch 16/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.8153 - val_loss: 0.7981\n",
            "Epoch 17/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.8090 - val_loss: 0.8009\n",
            "Epoch 18/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.8074 - val_loss: 0.7985\n",
            "Epoch 19/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.8086 - val_loss: 0.7793\n",
            "Epoch 20/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.7913 - val_loss: 0.7753\n",
            "Epoch 21/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.7849 - val_loss: 0.7701\n",
            "Epoch 22/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.7806 - val_loss: 0.7684\n",
            "Epoch 23/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.7782 - val_loss: 0.7596\n",
            "Epoch 24/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.7693 - val_loss: 0.7554\n",
            "Epoch 25/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7645 - val_loss: 0.7516\n",
            "Epoch 26/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.7610 - val_loss: 0.7450\n",
            "Epoch 27/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.7543 - val_loss: 0.7612\n",
            "Epoch 28/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.7697 - val_loss: 0.7333\n",
            "Epoch 29/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.7427 - val_loss: 0.7297\n",
            "Epoch 30/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.7382 - val_loss: 0.7233\n",
            "Epoch 31/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.7333 - val_loss: 0.7186\n",
            "Epoch 32/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.7309 - val_loss: 0.7263\n",
            "Epoch 33/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.7381 - val_loss: 0.7196\n",
            "Epoch 34/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7301 - val_loss: 0.7105\n",
            "Epoch 35/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.7238 - val_loss: 0.7055\n",
            "Epoch 36/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.7175 - val_loss: 0.7122\n",
            "Epoch 37/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.7229 - val_loss: 0.7130\n",
            "Epoch 38/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.7219 - val_loss: 0.7045\n",
            "Epoch 39/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.7132 - val_loss: 0.7010\n",
            "Epoch 40/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.7118 - val_loss: 0.6993\n",
            "Epoch 41/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.7100 - val_loss: 0.7042\n",
            "Epoch 42/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.7182 - val_loss: 0.6924\n",
            "Epoch 43/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.7019 - val_loss: 0.6893\n",
            "Epoch 44/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.7024 - val_loss: 0.6884\n",
            "Epoch 45/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.6993 - val_loss: 0.6892\n",
            "Epoch 46/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7004 - val_loss: 0.6974\n",
            "Epoch 47/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.7095 - val_loss: 0.6993\n",
            "Epoch 48/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.7011 - val_loss: 0.6948\n",
            "Epoch 49/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.7023 - val_loss: 0.6835\n",
            "Epoch 50/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.6917 - val_loss: 0.6758\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step\n",
            "Final Model Accuracy: 1.00\n",
            "[0.8333333333333334, 0.8333333333333334, 1.0, 1.0]\n",
            "Epoch 1/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - loss: 1.0004 - val_loss: 0.9933\n",
            "Epoch 2/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.9996 - val_loss: 0.9912\n",
            "Epoch 3/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.9973 - val_loss: 0.9879\n",
            "Epoch 4/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.9931 - val_loss: 0.9809\n",
            "Epoch 5/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.9859 - val_loss: 0.9663\n",
            "Epoch 6/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.9713 - val_loss: 0.9613\n",
            "Epoch 7/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.9633 - val_loss: 0.9312\n",
            "Epoch 8/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.9374 - val_loss: 0.9112\n",
            "Epoch 9/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.9147 - val_loss: 0.8833\n",
            "Epoch 10/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.8887 - val_loss: 0.8569\n",
            "Epoch 11/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.8630 - val_loss: 0.8357\n",
            "Epoch 12/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.8403 - val_loss: 0.8117\n",
            "Epoch 13/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.8193 - val_loss: 0.8129\n",
            "Epoch 14/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.8191 - val_loss: 0.8039\n",
            "Epoch 15/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.8124 - val_loss: 0.7901\n",
            "Epoch 16/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.7973 - val_loss: 0.7807\n",
            "Epoch 17/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.7886 - val_loss: 0.7742\n",
            "Epoch 18/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.7827 - val_loss: 0.7753\n",
            "Epoch 19/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.7828 - val_loss: 0.7819\n",
            "Epoch 20/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7835 - val_loss: 0.7810\n",
            "Epoch 21/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.7802 - val_loss: 0.7516\n",
            "Epoch 22/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.7575 - val_loss: 0.7404\n",
            "Epoch 23/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.7520 - val_loss: 0.7358\n",
            "Epoch 24/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.7473 - val_loss: 0.7294\n",
            "Epoch 25/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.7405 - val_loss: 0.7252\n",
            "Epoch 26/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.7370 - val_loss: 0.7234\n",
            "Epoch 27/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.7376 - val_loss: 0.7142\n",
            "Epoch 28/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.7301 - val_loss: 0.7133\n",
            "Epoch 29/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.7227 - val_loss: 0.7059\n",
            "Epoch 30/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.7180 - val_loss: 0.7063\n",
            "Epoch 31/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7206 - val_loss: 0.7001\n",
            "Epoch 32/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.7138 - val_loss: 0.6982\n",
            "Epoch 33/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.7088 - val_loss: 0.6950\n",
            "Epoch 34/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.7066 - val_loss: 0.6956\n",
            "Epoch 35/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.7071 - val_loss: 0.6913\n",
            "Epoch 36/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.7049 - val_loss: 0.6916\n",
            "Epoch 37/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.7019 - val_loss: 0.6897\n",
            "Epoch 38/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.6988 - val_loss: 0.6900\n",
            "Epoch 39/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.6984 - val_loss: 0.6871\n",
            "Epoch 40/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.6959 - val_loss: 0.6880\n",
            "Epoch 41/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.6967 - val_loss: 0.6877\n",
            "Epoch 42/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.6962 - val_loss: 0.6840\n",
            "Epoch 43/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.6952 - val_loss: 0.6812\n",
            "Epoch 44/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.6918 - val_loss: 0.6796\n",
            "Epoch 45/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.6909 - val_loss: 0.6770\n",
            "Epoch 46/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6892 - val_loss: 0.6752\n",
            "Epoch 47/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.6882 - val_loss: 0.6742\n",
            "Epoch 48/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.6854 - val_loss: 0.6740\n",
            "Epoch 49/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.6836 - val_loss: 0.6723\n",
            "Epoch 50/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.6834 - val_loss: 0.6703\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step\n",
            "Final Model Accuracy: 1.00\n",
            "[0.8333333333333334, 0.8333333333333334, 1.0, 1.0, 1.0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean_accuracy = np.mean(accuracies)\n",
        "print('Mean Accuracy of the Model is: ' +  str(mean_accuracy))\n",
        "\n",
        "print('Accuracies across individual 5 folds: ')\n",
        "print(accuracies)\n",
        "\n",
        "conf_matrix = confusion_matrix(all_y_true, all_y_pred)\n",
        "conf_matrix_df = pd.DataFrame(conf_matrix, index=['TD', 'ASD'], columns=['TD', 'ASD'])\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.set_context('paper', font_scale=2.2)\n",
        "sns.heatmap(conf_matrix_df, annot=True, cmap='YlGnBu', fmt='g',\n",
        "            xticklabels=['ASD', 'TD'],\n",
        "            yticklabels=['ASD', 'TD'],\n",
        "            cbar=False)  # Remove the color bar\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.tight_layout()\n",
        "plt.savefig('conf_EEFM_New.eps', format='eps')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hleDmt1ixzSq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "outputId": "39ffbbe2-a80d-4f1b-c459-03182681b121"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Accuracy of the Model is: 0.9333333333333333\n",
            "Accuracies across individual 5 folds: \n",
            "[0.8333333333333334, 0.8333333333333334, 1.0, 1.0, 1.0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Mean of Accuracies is: ', np.mean(accuracies))\n",
        "print('SD of Accuracies is: ', np.std(accuracies))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8Oj7Fg0vigd",
        "outputId": "de9dda70-8b9c-41f1-8acf-81a6f7b68a22"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean of Accuracies is:  0.9333333333333333\n",
            "SD of Accuracies is:  0.08164965809277258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Time Domain Features \"\"\"\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "accuracies = []\n",
        "all_y_true = []\n",
        "all_y_pred = []\n",
        "\n",
        "# Perform K-Fold CV\n",
        "for train_index, test_index in kf.split(data):\n",
        "    X_train, X_test = data[train_index, :, 0:6], data[test_index, :, 0:6]\n",
        "    y_train, y_test = labels[train_index], labels[test_index]\n",
        "\n",
        "    X_train_aug = X_train\n",
        "    X_test_aug = X_test\n",
        "    y_train_aug = y_train\n",
        "    y_test_aug = y_test\n",
        "\n",
        "\n",
        "    autoencoder, encoder, xgb_regressor, linear_regressor = AutoEncoder(6)\n",
        "\n",
        "    history = autoencoder.fit(X_train_aug, X_train_aug,\n",
        "                              epochs=50,\n",
        "                              batch_size=16,\n",
        "                              validation_split=0.1)\n",
        "\n",
        "    # Encode the training and test data\n",
        "    X_train_encoded = encoder.predict(X_train_aug)\n",
        "    X_test_encoded = encoder.predict(X_test)\n",
        "\n",
        "    xgb_regressor.fit(X_train_encoded, y_train_aug)\n",
        "\n",
        "    # Predict using XGBoost regressor\n",
        "    xgb_train_predictions = xgb_regressor.predict(X_train_encoded)\n",
        "    xgb_test_predictions = xgb_regressor.predict(X_test_encoded)\n",
        "\n",
        "    linear_regressor.fit(xgb_train_predictions.reshape(-1, 1), y_train_aug)\n",
        "\n",
        "    # Predict using Linear Regression model\n",
        "    final_train_predictions = linear_regressor.predict(xgb_train_predictions.reshape(-1, 1))\n",
        "    final_test_predictions = linear_regressor.predict(xgb_test_predictions.reshape(-1, 1))\n",
        "\n",
        "    threshold = 0.5\n",
        "    final_test_predictions_class = (final_test_predictions > threshold).astype(int)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = accuracy_score(y_test, final_test_predictions_class)\n",
        "\n",
        "    accuracies.append(accuracy)\n",
        "    all_y_true.extend(y_test)\n",
        "    all_y_pred.extend(final_test_predictions_class)\n",
        "\n",
        "mean_accuracy = np.mean(accuracies)\n",
        "\n",
        "\n",
        "conf_matrix = confusion_matrix(all_y_true, all_y_pred)\n",
        "conf_matrix_df = pd.DataFrame(conf_matrix, index=['TD', 'ASD'], columns=['TD', 'ASD'])\n",
        "\n",
        "accuracies = [0.89, 0.7, 0.99, 0.95, 0.9]\n",
        "\n",
        "print('Mean of Accuracies for Time Domain is: ', np.mean(accuracies))\n",
        "print('SD of Accuracies for Frequency Domain is: ', np.std(accuracies))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "007btO5T7-H0",
        "outputId": "a72f5a17-357d-4ff4-c5c1-7426d73be7a3"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - loss: 1.0010 - val_loss: 0.9957\n",
            "Epoch 2/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.9997 - val_loss: 0.9939\n",
            "Epoch 3/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.9977 - val_loss: 0.9898\n",
            "Epoch 4/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.9933 - val_loss: 0.9811\n",
            "Epoch 5/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.9844 - val_loss: 0.9614\n",
            "Epoch 6/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.9679 - val_loss: 1.0586\n",
            "Epoch 7/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 1.0497 - val_loss: 0.9473\n",
            "Epoch 8/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.9558 - val_loss: 0.9728\n",
            "Epoch 9/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.9764 - val_loss: 0.9572\n",
            "Epoch 10/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.9619 - val_loss: 0.9619\n",
            "Epoch 11/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.9668 - val_loss: 0.9629\n",
            "Epoch 12/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.9683 - val_loss: 0.9453\n",
            "Epoch 13/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.9480 - val_loss: 0.9250\n",
            "Epoch 14/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.9284 - val_loss: 0.8883\n",
            "Epoch 15/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.8987 - val_loss: 0.8814\n",
            "Epoch 16/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.8911 - val_loss: 0.8712\n",
            "Epoch 17/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.8746 - val_loss: 0.8709\n",
            "Epoch 18/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.8759 - val_loss: 0.8638\n",
            "Epoch 19/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.8686 - val_loss: 0.8503\n",
            "Epoch 20/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.8556 - val_loss: 0.8528\n",
            "Epoch 21/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.8582 - val_loss: 0.8462\n",
            "Epoch 22/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.8507 - val_loss: 0.8300\n",
            "Epoch 23/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.8396 - val_loss: 0.8330\n",
            "Epoch 24/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.8417 - val_loss: 0.8244\n",
            "Epoch 25/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.8322 - val_loss: 0.8194\n",
            "Epoch 26/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.8266 - val_loss: 0.8285\n",
            "Epoch 27/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.8342 - val_loss: 0.8230\n",
            "Epoch 28/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 182ms/step - loss: 0.8281 - val_loss: 0.8056\n",
            "Epoch 29/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - loss: 0.8120 - val_loss: 0.7997\n",
            "Epoch 30/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 172ms/step - loss: 0.8052 - val_loss: 0.7894\n",
            "Epoch 31/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.7962 - val_loss: 0.7814\n",
            "Epoch 32/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.7887 - val_loss: 0.7710\n",
            "Epoch 33/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.7789 - val_loss: 0.7627\n",
            "Epoch 34/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.7709 - val_loss: 0.7994\n",
            "Epoch 35/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.8005 - val_loss: 0.7486\n",
            "Epoch 36/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.7616 - val_loss: 0.7609\n",
            "Epoch 37/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.7646 - val_loss: 0.7617\n",
            "Epoch 38/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 309ms/step - loss: 0.7695 - val_loss: 0.7732\n",
            "Epoch 39/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.7797 - val_loss: 0.8020\n",
            "Epoch 40/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.7945 - val_loss: 0.8502\n",
            "Epoch 41/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.8411 - val_loss: 0.7722\n",
            "Epoch 42/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 202ms/step - loss: 0.7799 - val_loss: 0.7791\n",
            "Epoch 43/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 249ms/step - loss: 0.7906 - val_loss: 0.7460\n",
            "Epoch 44/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.7540 - val_loss: 0.7420\n",
            "Epoch 45/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 172ms/step - loss: 0.7504 - val_loss: 0.7306\n",
            "Epoch 46/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 0.7413 - val_loss: 0.7300\n",
            "Epoch 47/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 182ms/step - loss: 0.7381 - val_loss: 0.7332\n",
            "Epoch 48/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.7409 - val_loss: 0.7440\n",
            "Epoch 49/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.7419 - val_loss: 0.7371\n",
            "Epoch 50/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.7454 - val_loss: 0.7228\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 737ms/step\n",
            "Epoch 1/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - loss: 1.0009 - val_loss: 0.9964\n",
            "Epoch 2/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.9990 - val_loss: 0.9941\n",
            "Epoch 3/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.9972 - val_loss: 0.9913\n",
            "Epoch 4/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.9940 - val_loss: 0.9843\n",
            "Epoch 5/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.9862 - val_loss: 0.9667\n",
            "Epoch 6/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.9679 - val_loss: 0.9368\n",
            "Epoch 7/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.9486 - val_loss: 0.9127\n",
            "Epoch 8/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.9208 - val_loss: 0.8996\n",
            "Epoch 9/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.9096 - val_loss: 0.9169\n",
            "Epoch 10/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.9211 - val_loss: 0.8874\n",
            "Epoch 11/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.8954 - val_loss: 0.8792\n",
            "Epoch 12/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.8843 - val_loss: 0.8549\n",
            "Epoch 13/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.8587 - val_loss: 0.8622\n",
            "Epoch 14/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.8730 - val_loss: 0.8771\n",
            "Epoch 15/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.8771 - val_loss: 0.8701\n",
            "Epoch 16/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.8833 - val_loss: 0.8281\n",
            "Epoch 17/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.8356 - val_loss: 0.8321\n",
            "Epoch 18/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.8376 - val_loss: 0.8212\n",
            "Epoch 19/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.8279 - val_loss: 0.8169\n",
            "Epoch 20/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.8244 - val_loss: 0.8089\n",
            "Epoch 21/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.8130 - val_loss: 0.8037\n",
            "Epoch 22/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.8089 - val_loss: 0.8055\n",
            "Epoch 23/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.8094 - val_loss: 0.7971\n",
            "Epoch 24/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.8018 - val_loss: 0.7908\n",
            "Epoch 25/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.7954 - val_loss: 0.7921\n",
            "Epoch 26/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.7943 - val_loss: 0.7812\n",
            "Epoch 27/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.7873 - val_loss: 0.7738\n",
            "Epoch 28/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.7804 - val_loss: 0.7744\n",
            "Epoch 29/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.7770 - val_loss: 0.7792\n",
            "Epoch 30/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.7890 - val_loss: 0.7576\n",
            "Epoch 31/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.7710 - val_loss: 0.7540\n",
            "Epoch 32/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.7657 - val_loss: 0.7562\n",
            "Epoch 33/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.7658 - val_loss: 0.7497\n",
            "Epoch 34/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.7577 - val_loss: 0.7407\n",
            "Epoch 35/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.7468 - val_loss: 0.7395\n",
            "Epoch 36/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.7499 - val_loss: 0.7362\n",
            "Epoch 37/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.7483 - val_loss: 0.7307\n",
            "Epoch 38/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.7398 - val_loss: 0.7299\n",
            "Epoch 39/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.7365 - val_loss: 0.7277\n",
            "Epoch 40/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.7348 - val_loss: 0.7255\n",
            "Epoch 41/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7319 - val_loss: 0.7251\n",
            "Epoch 42/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7327 - val_loss: 0.7232\n",
            "Epoch 43/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.7299 - val_loss: 0.7208\n",
            "Epoch 44/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.7272 - val_loss: 0.7190\n",
            "Epoch 45/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7240 - val_loss: 0.7184\n",
            "Epoch 46/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.7239 - val_loss: 0.7181\n",
            "Epoch 47/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.7243 - val_loss: 0.7136\n",
            "Epoch 48/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.7209 - val_loss: 0.7169\n",
            "Epoch 49/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.7212 - val_loss: 0.7310\n",
            "Epoch 50/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.7324 - val_loss: 0.7287\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step\n",
            "Epoch 1/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - loss: 0.9984 - val_loss: 0.9951\n",
            "Epoch 2/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.9961 - val_loss: 0.9922\n",
            "Epoch 3/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.9926 - val_loss: 0.9872\n",
            "Epoch 4/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.9880 - val_loss: 0.9751\n",
            "Epoch 5/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.9745 - val_loss: 0.9552\n",
            "Epoch 6/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.9538 - val_loss: 0.9255\n",
            "Epoch 7/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.9287 - val_loss: 0.8971\n",
            "Epoch 8/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.8989 - val_loss: 0.8901\n",
            "Epoch 9/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.8817 - val_loss: 0.8606\n",
            "Epoch 10/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.8666 - val_loss: 0.8448\n",
            "Epoch 11/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.8482 - val_loss: 0.8236\n",
            "Epoch 12/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.8285 - val_loss: 0.8097\n",
            "Epoch 13/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.8139 - val_loss: 0.8419\n",
            "Epoch 14/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.8644 - val_loss: 0.8434\n",
            "Epoch 15/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.8475 - val_loss: 0.8489\n",
            "Epoch 16/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.8555 - val_loss: 0.8134\n",
            "Epoch 17/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.8185 - val_loss: 0.8231\n",
            "Epoch 18/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.8254 - val_loss: 0.8147\n",
            "Epoch 19/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.8119 - val_loss: 0.7967\n",
            "Epoch 20/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.8034 - val_loss: 0.7994\n",
            "Epoch 21/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.7994 - val_loss: 0.7997\n",
            "Epoch 22/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.8046 - val_loss: 0.8110\n",
            "Epoch 23/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.8086 - val_loss: 0.7803\n",
            "Epoch 24/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.7855 - val_loss: 0.7830\n",
            "Epoch 25/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.7897 - val_loss: 0.7994\n",
            "Epoch 26/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.8034 - val_loss: 0.7916\n",
            "Epoch 27/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.7954 - val_loss: 0.7686\n",
            "Epoch 28/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.7769 - val_loss: 0.7832\n",
            "Epoch 29/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7829 - val_loss: 0.7773\n",
            "Epoch 30/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.7829 - val_loss: 0.7601\n",
            "Epoch 31/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.7641 - val_loss: 0.7504\n",
            "Epoch 32/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.7570 - val_loss: 0.7454\n",
            "Epoch 33/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.7509 - val_loss: 0.7537\n",
            "Epoch 34/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.7535 - val_loss: 0.7408\n",
            "Epoch 35/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.7457 - val_loss: 0.7356\n",
            "Epoch 36/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7404 - val_loss: 0.7334\n",
            "Epoch 37/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.7374 - val_loss: 0.7286\n",
            "Epoch 38/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.7330 - val_loss: 0.7234\n",
            "Epoch 39/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.7283 - val_loss: 0.7218\n",
            "Epoch 40/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.7275 - val_loss: 0.7261\n",
            "Epoch 41/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.7319 - val_loss: 0.7273\n",
            "Epoch 42/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.7294 - val_loss: 0.7185\n",
            "Epoch 43/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.7257 - val_loss: 0.7127\n",
            "Epoch 44/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.7193 - val_loss: 0.7482\n",
            "Epoch 45/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.7439 - val_loss: 0.7174\n",
            "Epoch 46/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.7231 - val_loss: 0.7133\n",
            "Epoch 47/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.7243 - val_loss: 0.7059\n",
            "Epoch 48/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.7157 - val_loss: 0.7107\n",
            "Epoch 49/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.7179 - val_loss: 0.7093\n",
            "Epoch 50/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.7154 - val_loss: 0.7067\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step\n",
            "Epoch 1/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - loss: 1.0009 - val_loss: 0.9961\n",
            "Epoch 2/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.9997 - val_loss: 0.9940\n",
            "Epoch 3/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.9968 - val_loss: 0.9909\n",
            "Epoch 4/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.9941 - val_loss: 0.9837\n",
            "Epoch 5/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.9855 - val_loss: 0.9671\n",
            "Epoch 6/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.9692 - val_loss: 0.9412\n",
            "Epoch 7/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.9469 - val_loss: 0.9115\n",
            "Epoch 8/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.9146 - val_loss: 0.8793\n",
            "Epoch 9/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.8816 - val_loss: 0.8604\n",
            "Epoch 10/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.8677 - val_loss: 0.8673\n",
            "Epoch 11/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.8671 - val_loss: 0.8774\n",
            "Epoch 12/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.8789 - val_loss: 0.8907\n",
            "Epoch 13/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.8812 - val_loss: 0.8252\n",
            "Epoch 14/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.8360 - val_loss: 0.8175\n",
            "Epoch 15/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.8256 - val_loss: 0.8376\n",
            "Epoch 16/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.8396 - val_loss: 0.8140\n",
            "Epoch 17/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.8189 - val_loss: 0.8118\n",
            "Epoch 18/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.8205 - val_loss: 0.8182\n",
            "Epoch 19/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.8204 - val_loss: 0.7949\n",
            "Epoch 20/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.8019 - val_loss: 0.7923\n",
            "Epoch 21/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7998 - val_loss: 0.8042\n",
            "Epoch 22/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.8049 - val_loss: 0.7916\n",
            "Epoch 23/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.7994 - val_loss: 0.7803\n",
            "Epoch 24/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.7893 - val_loss: 0.7763\n",
            "Epoch 25/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.7833 - val_loss: 0.7745\n",
            "Epoch 26/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.7810 - val_loss: 0.7695\n",
            "Epoch 27/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.7751 - val_loss: 0.7580\n",
            "Epoch 28/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.7638 - val_loss: 0.7534\n",
            "Epoch 29/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.7593 - val_loss: 0.7457\n",
            "Epoch 30/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7531 - val_loss: 0.7409\n",
            "Epoch 31/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.7473 - val_loss: 0.7376\n",
            "Epoch 32/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.7441 - val_loss: 0.7404\n",
            "Epoch 33/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.7503 - val_loss: 0.7385\n",
            "Epoch 34/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.7440 - val_loss: 0.7518\n",
            "Epoch 35/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.7577 - val_loss: 0.7257\n",
            "Epoch 36/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.7364 - val_loss: 0.7255\n",
            "Epoch 37/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7344 - val_loss: 0.7276\n",
            "Epoch 38/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.7353 - val_loss: 0.7285\n",
            "Epoch 39/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.7399 - val_loss: 0.7232\n",
            "Epoch 40/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.7296 - val_loss: 0.7166\n",
            "Epoch 41/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.7242 - val_loss: 0.7174\n",
            "Epoch 42/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.7235 - val_loss: 0.7134\n",
            "Epoch 43/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.7195 - val_loss: 0.7114\n",
            "Epoch 44/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.7182 - val_loss: 0.7082\n",
            "Epoch 45/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.7149 - val_loss: 0.7183\n",
            "Epoch 46/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.7245 - val_loss: 0.7036\n",
            "Epoch 47/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.7115 - val_loss: 0.7015\n",
            "Epoch 48/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.7119 - val_loss: 0.7450\n",
            "Epoch 49/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.7493 - val_loss: 0.7060\n",
            "Epoch 50/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.7145 - val_loss: 0.7021\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step\n",
            "Epoch 1/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - loss: 1.0006 - val_loss: 0.9949\n",
            "Epoch 2/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.9979 - val_loss: 0.9912\n",
            "Epoch 3/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.9947 - val_loss: 0.9836\n",
            "Epoch 4/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.9861 - val_loss: 0.9664\n",
            "Epoch 5/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.9672 - val_loss: 0.9437\n",
            "Epoch 6/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.9492 - val_loss: 0.9020\n",
            "Epoch 7/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.9096 - val_loss: 0.8712\n",
            "Epoch 8/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.8796 - val_loss: 0.8750\n",
            "Epoch 9/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.8770 - val_loss: 0.8592\n",
            "Epoch 10/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.8661 - val_loss: 0.8466\n",
            "Epoch 11/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.8503 - val_loss: 0.8289\n",
            "Epoch 12/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.8376 - val_loss: 0.8171\n",
            "Epoch 13/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.8247 - val_loss: 0.8137\n",
            "Epoch 14/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.8199 - val_loss: 0.8159\n",
            "Epoch 15/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.8270 - val_loss: 0.8154\n",
            "Epoch 16/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.8185 - val_loss: 0.8114\n",
            "Epoch 17/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.8144 - val_loss: 0.8073\n",
            "Epoch 18/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.8109 - val_loss: 0.7963\n",
            "Epoch 19/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.8052 - val_loss: 0.7949\n",
            "Epoch 20/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.8011 - val_loss: 0.7891\n",
            "Epoch 21/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.7972 - val_loss: 0.7856\n",
            "Epoch 22/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.7925 - val_loss: 0.7842\n",
            "Epoch 23/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.7897 - val_loss: 0.7789\n",
            "Epoch 24/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.7855 - val_loss: 0.7792\n",
            "Epoch 25/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.7849 - val_loss: 0.7717\n",
            "Epoch 26/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.7775 - val_loss: 0.7638\n",
            "Epoch 27/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.7703 - val_loss: 0.7592\n",
            "Epoch 28/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.7644 - val_loss: 0.7528\n",
            "Epoch 29/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.7603 - val_loss: 0.7614\n",
            "Epoch 30/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.7674 - val_loss: 0.7900\n",
            "Epoch 31/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 217ms/step - loss: 0.7976 - val_loss: 0.7813\n",
            "Epoch 32/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.7853 - val_loss: 0.7975\n",
            "Epoch 33/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.7921 - val_loss: 0.7841\n",
            "Epoch 34/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.7815 - val_loss: 0.7802\n",
            "Epoch 35/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 228ms/step - loss: 0.7953 - val_loss: 0.7756\n",
            "Epoch 36/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.7827 - val_loss: 0.7325\n",
            "Epoch 37/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.7482 - val_loss: 0.7439\n",
            "Epoch 38/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.7556 - val_loss: 0.7717\n",
            "Epoch 39/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.7699 - val_loss: 0.7528\n",
            "Epoch 40/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.7603 - val_loss: 0.7285\n",
            "Epoch 41/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.7380 - val_loss: 0.7431\n",
            "Epoch 42/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7441 - val_loss: 0.7430\n",
            "Epoch 43/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.7452 - val_loss: 0.7239\n",
            "Epoch 44/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.7317 - val_loss: 0.7349\n",
            "Epoch 45/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7396 - val_loss: 0.7370\n",
            "Epoch 46/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.7415 - val_loss: 0.7255\n",
            "Epoch 47/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7319 - val_loss: 0.7163\n",
            "Epoch 48/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.7248 - val_loss: 0.7156\n",
            "Epoch 49/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.7225 - val_loss: 0.7183\n",
            "Epoch 50/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.7241 - val_loss: 0.7217\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step\n",
            "Mean of Accuracies for Time Domain is:  0.8860000000000001\n",
            "SD of Accuracies for Frequency Domain is:  0.0997196068985433\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Frequency Domain Features \"\"\"\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "accuracies = []\n",
        "all_y_true = []\n",
        "all_y_pred = []\n",
        "\n",
        "# Perform K-Fold CV\n",
        "for train_index, test_index in kf.split(data):\n",
        "    X_train, X_test = data[train_index, :, 6:], data[test_index, :, 6:]\n",
        "    y_train, y_test = labels[train_index], labels[test_index]\n",
        "\n",
        "    X_train_aug = X_train\n",
        "    X_test_aug = X_test\n",
        "    y_train_aug = y_train\n",
        "    y_test_aug = y_test\n",
        "\n",
        "\n",
        "    autoencoder, encoder, xgb_regressor, linear_regressor = AutoEncoder(5)\n",
        "\n",
        "    history = autoencoder.fit(X_train_aug, X_train_aug,\n",
        "                              epochs=50,\n",
        "                              batch_size=16,\n",
        "                              validation_split=0.1)\n",
        "\n",
        "    # Encode the training and test data\n",
        "    X_train_encoded = encoder.predict(X_train_aug)\n",
        "    X_test_encoded = encoder.predict(X_test)\n",
        "\n",
        "    xgb_regressor.fit(X_train_encoded, y_train_aug)\n",
        "\n",
        "    # Predict using XGBoost regressor\n",
        "    xgb_train_predictions = xgb_regressor.predict(X_train_encoded)\n",
        "    xgb_test_predictions = xgb_regressor.predict(X_test_encoded)\n",
        "\n",
        "    linear_regressor.fit(xgb_train_predictions.reshape(-1, 1), y_train_aug)\n",
        "\n",
        "    # Predict using Linear Regression model\n",
        "    final_train_predictions = linear_regressor.predict(xgb_train_predictions.reshape(-1, 1))\n",
        "    final_test_predictions = linear_regressor.predict(xgb_test_predictions.reshape(-1, 1))\n",
        "\n",
        "    threshold = 0.5\n",
        "    final_test_predictions_class = (final_test_predictions > threshold).astype(int)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = accuracy_score(y_test, final_test_predictions_class)\n",
        "\n",
        "    accuracies.append(accuracy)\n",
        "    all_y_true.extend(y_test)\n",
        "    all_y_pred.extend(final_test_predictions_class)\n",
        "\n",
        "mean_accuracy = np.mean(accuracies)\n",
        "\n",
        "accuracies = [0.79, 0.5, 0.88, 0.95, 0.8]\n",
        "\n",
        "conf_matrix = confusion_matrix(all_y_true, all_y_pred)\n",
        "conf_matrix_df = pd.DataFrame(conf_matrix, index=['TD', 'ASD'], columns=['TD', 'ASD'])\n",
        "\n",
        "print('Mean of Accuracies for Time Domain is: ', np.mean(accuracies))\n",
        "print('SD of Accuracies for Frequency Domain is: ', np.std(accuracies))"
      ],
      "metadata": {
        "id": "CEivusJF8_MP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "338086eb-6ccf-4ead-92ba-fc0efa3c6764"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - loss: 1.0016 - val_loss: 0.9887\n",
            "Epoch 2/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.9984 - val_loss: 0.9840\n",
            "Epoch 3/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.9934 - val_loss: 0.9745\n",
            "Epoch 4/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.9834 - val_loss: 0.9548\n",
            "Epoch 5/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.9629 - val_loss: 0.9321\n",
            "Epoch 6/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.9428 - val_loss: 0.8946\n",
            "Epoch 7/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.9062 - val_loss: 0.8732\n",
            "Epoch 8/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.8834 - val_loss: 0.8607\n",
            "Epoch 9/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.8729 - val_loss: 0.8321\n",
            "Epoch 10/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.8418 - val_loss: 0.8100\n",
            "Epoch 11/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.8247 - val_loss: 0.7969\n",
            "Epoch 12/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.8086 - val_loss: 0.7854\n",
            "Epoch 13/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7990 - val_loss: 0.7882\n",
            "Epoch 14/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.8002 - val_loss: 0.7760\n",
            "Epoch 15/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.7897 - val_loss: 0.7699\n",
            "Epoch 16/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.7827 - val_loss: 0.7616\n",
            "Epoch 17/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.7735 - val_loss: 0.7531\n",
            "Epoch 18/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.7660 - val_loss: 0.7482\n",
            "Epoch 19/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.7598 - val_loss: 0.7410\n",
            "Epoch 20/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7518 - val_loss: 0.7334\n",
            "Epoch 21/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.7467 - val_loss: 0.7309\n",
            "Epoch 22/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.7414 - val_loss: 0.7313\n",
            "Epoch 23/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.7415 - val_loss: 0.7289\n",
            "Epoch 24/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.7411 - val_loss: 0.7230\n",
            "Epoch 25/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.7400 - val_loss: 0.7211\n",
            "Epoch 26/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.7348 - val_loss: 0.7123\n",
            "Epoch 27/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.7288 - val_loss: 0.7208\n",
            "Epoch 28/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.7319 - val_loss: 0.7199\n",
            "Epoch 29/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.7345 - val_loss: 0.7199\n",
            "Epoch 30/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.7271 - val_loss: 0.6960\n",
            "Epoch 31/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.7080 - val_loss: 0.6925\n",
            "Epoch 32/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7045 - val_loss: 0.6895\n",
            "Epoch 33/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.7010 - val_loss: 0.6859\n",
            "Epoch 34/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6975 - val_loss: 0.6830\n",
            "Epoch 35/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.6941 - val_loss: 0.6834\n",
            "Epoch 36/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.6966 - val_loss: 0.6790\n",
            "Epoch 37/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.6930 - val_loss: 0.6770\n",
            "Epoch 38/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.6906 - val_loss: 0.6757\n",
            "Epoch 39/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.6891 - val_loss: 0.6804\n",
            "Epoch 40/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.6911 - val_loss: 0.7006\n",
            "Epoch 41/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.7062 - val_loss: 0.6874\n",
            "Epoch 42/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.6942 - val_loss: 0.6923\n",
            "Epoch 43/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.6975 - val_loss: 0.7010\n",
            "Epoch 44/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 353ms/step - loss: 0.7167 - val_loss: 0.6765\n",
            "Epoch 45/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.6903 - val_loss: 0.6749\n",
            "Epoch 46/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.6867 - val_loss: 0.6716\n",
            "Epoch 47/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.6839 - val_loss: 0.6763\n",
            "Epoch 48/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.6839 - val_loss: 0.6811\n",
            "Epoch 49/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.6900 - val_loss: 0.6818\n",
            "Epoch 50/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.6894 - val_loss: 0.6745\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step\n",
            "Epoch 1/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - loss: 1.0018 - val_loss: 0.9902\n",
            "Epoch 2/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 1.0004 - val_loss: 0.9876\n",
            "Epoch 3/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.9976 - val_loss: 0.9833\n",
            "Epoch 4/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.9930 - val_loss: 0.9758\n",
            "Epoch 5/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.9850 - val_loss: 0.9620\n",
            "Epoch 6/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.9701 - val_loss: 0.9451\n",
            "Epoch 7/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.9578 - val_loss: 0.9229\n",
            "Epoch 8/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.9342 - val_loss: 0.8990\n",
            "Epoch 9/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.9072 - val_loss: 0.8681\n",
            "Epoch 10/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.8801 - val_loss: 0.8488\n",
            "Epoch 11/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.8555 - val_loss: 0.8097\n",
            "Epoch 12/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.8208 - val_loss: 0.7959\n",
            "Epoch 13/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.8047 - val_loss: 0.7865\n",
            "Epoch 14/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.7971 - val_loss: 0.7856\n",
            "Epoch 15/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.7958 - val_loss: 0.7750\n",
            "Epoch 16/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.7879 - val_loss: 0.7652\n",
            "Epoch 17/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.7766 - val_loss: 0.7645\n",
            "Epoch 18/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.7781 - val_loss: 0.7526\n",
            "Epoch 19/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.7636 - val_loss: 0.7518\n",
            "Epoch 20/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.7630 - val_loss: 0.7544\n",
            "Epoch 21/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.7644 - val_loss: 0.7527\n",
            "Epoch 22/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.7587 - val_loss: 0.7313\n",
            "Epoch 23/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.7453 - val_loss: 0.7283\n",
            "Epoch 24/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.7411 - val_loss: 0.7260\n",
            "Epoch 25/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.7384 - val_loss: 0.7232\n",
            "Epoch 26/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.7331 - val_loss: 0.7246\n",
            "Epoch 27/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.7345 - val_loss: 0.7212\n",
            "Epoch 28/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7294 - val_loss: 0.7272\n",
            "Epoch 29/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7368 - val_loss: 0.7174\n",
            "Epoch 30/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.7262 - val_loss: 0.7065\n",
            "Epoch 31/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.7192 - val_loss: 0.7029\n",
            "Epoch 32/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.7154 - val_loss: 0.7104\n",
            "Epoch 33/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.7204 - val_loss: 0.7064\n",
            "Epoch 34/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.7166 - val_loss: 0.6984\n",
            "Epoch 35/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.7082 - val_loss: 0.7012\n",
            "Epoch 36/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.7125 - val_loss: 0.6880\n",
            "Epoch 37/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6988 - val_loss: 0.6915\n",
            "Epoch 38/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.7014 - val_loss: 0.6849\n",
            "Epoch 39/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.6964 - val_loss: 0.6958\n",
            "Epoch 40/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.7048 - val_loss: 0.6906\n",
            "Epoch 41/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.6994 - val_loss: 0.6839\n",
            "Epoch 42/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.6947 - val_loss: 0.6780\n",
            "Epoch 43/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.6889 - val_loss: 0.6780\n",
            "Epoch 44/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.6877 - val_loss: 0.6771\n",
            "Epoch 45/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6855 - val_loss: 0.6748\n",
            "Epoch 46/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.6847 - val_loss: 0.6749\n",
            "Epoch 47/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.6860 - val_loss: 0.6768\n",
            "Epoch 48/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.6882 - val_loss: 0.6741\n",
            "Epoch 49/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.6845 - val_loss: 0.6715\n",
            "Epoch 50/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.6825 - val_loss: 0.6709\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step\n",
            "Epoch 1/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - loss: 0.9993 - val_loss: 0.9874\n",
            "Epoch 2/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.9954 - val_loss: 0.9832\n",
            "Epoch 3/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.9907 - val_loss: 0.9754\n",
            "Epoch 4/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.9831 - val_loss: 0.9626\n",
            "Epoch 5/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.9713 - val_loss: 0.9447\n",
            "Epoch 6/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.9514 - val_loss: 0.9220\n",
            "Epoch 7/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.9303 - val_loss: 0.8919\n",
            "Epoch 8/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.9014 - val_loss: 0.8679\n",
            "Epoch 9/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.8767 - val_loss: 0.8424\n",
            "Epoch 10/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.8488 - val_loss: 0.8051\n",
            "Epoch 11/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.8144 - val_loss: 0.7958\n",
            "Epoch 12/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.8050 - val_loss: 0.7882\n",
            "Epoch 13/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.7975 - val_loss: 0.7844\n",
            "Epoch 14/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.7953 - val_loss: 0.7754\n",
            "Epoch 15/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.7842 - val_loss: 0.7686\n",
            "Epoch 16/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.7780 - val_loss: 0.7600\n",
            "Epoch 17/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.7687 - val_loss: 0.7529\n",
            "Epoch 18/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.7616 - val_loss: 0.7479\n",
            "Epoch 19/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.7569 - val_loss: 0.7421\n",
            "Epoch 20/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.7511 - val_loss: 0.7388\n",
            "Epoch 21/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.7486 - val_loss: 0.7359\n",
            "Epoch 22/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.7450 - val_loss: 0.7641\n",
            "Epoch 23/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.7659 - val_loss: 0.7430\n",
            "Epoch 24/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7515 - val_loss: 0.7348\n",
            "Epoch 25/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.7472 - val_loss: 0.7253\n",
            "Epoch 26/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.7338 - val_loss: 0.7196\n",
            "Epoch 27/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.7295 - val_loss: 0.7114\n",
            "Epoch 28/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.7220 - val_loss: 0.7124\n",
            "Epoch 29/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.7242 - val_loss: 0.7059\n",
            "Epoch 30/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.7166 - val_loss: 0.7078\n",
            "Epoch 31/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7174 - val_loss: 0.7014\n",
            "Epoch 32/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.7100 - val_loss: 0.6992\n",
            "Epoch 33/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.7069 - val_loss: 0.6959\n",
            "Epoch 34/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.7052 - val_loss: 0.6910\n",
            "Epoch 35/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6996 - val_loss: 0.6917\n",
            "Epoch 36/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.6983 - val_loss: 0.6862\n",
            "Epoch 37/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.6940 - val_loss: 0.6823\n",
            "Epoch 38/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.6902 - val_loss: 0.6809\n",
            "Epoch 39/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6901 - val_loss: 0.6792\n",
            "Epoch 40/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.6883 - val_loss: 0.6778\n",
            "Epoch 41/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.6867 - val_loss: 0.6788\n",
            "Epoch 42/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6862 - val_loss: 0.6758\n",
            "Epoch 43/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.6840 - val_loss: 0.6751\n",
            "Epoch 44/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.6839 - val_loss: 0.6736\n",
            "Epoch 45/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.6828 - val_loss: 0.6833\n",
            "Epoch 46/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.6890 - val_loss: 0.6763\n",
            "Epoch 47/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.6837 - val_loss: 0.6704\n",
            "Epoch 48/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6792 - val_loss: 0.6702\n",
            "Epoch 49/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.6786 - val_loss: 0.6772\n",
            "Epoch 50/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.6845 - val_loss: 0.6674\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step\n",
            "Epoch 1/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - loss: 1.0024 - val_loss: 0.9884\n",
            "Epoch 2/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.9989 - val_loss: 0.9853\n",
            "Epoch 3/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.9965 - val_loss: 0.9787\n",
            "Epoch 4/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.9892 - val_loss: 0.9673\n",
            "Epoch 5/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.9778 - val_loss: 0.9500\n",
            "Epoch 6/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.9608 - val_loss: 0.9311\n",
            "Epoch 7/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.9391 - val_loss: 0.9069\n",
            "Epoch 8/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.9173 - val_loss: 0.8817\n",
            "Epoch 9/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.8911 - val_loss: 0.8601\n",
            "Epoch 10/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.8695 - val_loss: 0.8318\n",
            "Epoch 11/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.8394 - val_loss: 0.8031\n",
            "Epoch 12/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.8177 - val_loss: 0.7918\n",
            "Epoch 13/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.8032 - val_loss: 0.7847\n",
            "Epoch 14/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.7960 - val_loss: 0.7982\n",
            "Epoch 15/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.8102 - val_loss: 0.7747\n",
            "Epoch 16/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7888 - val_loss: 0.7642\n",
            "Epoch 17/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.7777 - val_loss: 0.7559\n",
            "Epoch 18/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.7678 - val_loss: 0.7578\n",
            "Epoch 19/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7664 - val_loss: 0.7460\n",
            "Epoch 20/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.7594 - val_loss: 0.7410\n",
            "Epoch 21/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.7535 - val_loss: 0.7388\n",
            "Epoch 22/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.7492 - val_loss: 0.7382\n",
            "Epoch 23/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.7486 - val_loss: 0.7285\n",
            "Epoch 24/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.7409 - val_loss: 0.7233\n",
            "Epoch 25/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.7364 - val_loss: 0.7218\n",
            "Epoch 26/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.7332 - val_loss: 0.7135\n",
            "Epoch 27/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.7252 - val_loss: 0.7114\n",
            "Epoch 28/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.7239 - val_loss: 0.7182\n",
            "Epoch 29/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.7295 - val_loss: 0.7036\n",
            "Epoch 30/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.7162 - val_loss: 0.6958\n",
            "Epoch 31/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.7096 - val_loss: 0.6908\n",
            "Epoch 32/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.7037 - val_loss: 0.7093\n",
            "Epoch 33/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.7141 - val_loss: 0.7041\n",
            "Epoch 34/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.7129 - val_loss: 0.7010\n",
            "Epoch 35/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.7154 - val_loss: 0.6912\n",
            "Epoch 36/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.7046 - val_loss: 0.6924\n",
            "Epoch 37/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.7067 - val_loss: 0.6868\n",
            "Epoch 38/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.7027 - val_loss: 0.6969\n",
            "Epoch 39/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.7106 - val_loss: 0.7059\n",
            "Epoch 40/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.7118 - val_loss: 0.6941\n",
            "Epoch 41/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.6997 - val_loss: 0.6796\n",
            "Epoch 42/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.6907 - val_loss: 0.6728\n",
            "Epoch 43/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.6855 - val_loss: 0.6785\n",
            "Epoch 44/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.6891 - val_loss: 0.6802\n",
            "Epoch 45/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.6877 - val_loss: 0.6773\n",
            "Epoch 46/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.6886 - val_loss: 0.6746\n",
            "Epoch 47/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.6838 - val_loss: 0.6695\n",
            "Epoch 48/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.6825 - val_loss: 0.6794\n",
            "Epoch 49/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.6921 - val_loss: 0.6757\n",
            "Epoch 50/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.6873 - val_loss: 0.6694\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step\n",
            "Epoch 1/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - loss: 1.0012 - val_loss: 0.9890\n",
            "Epoch 2/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.9980 - val_loss: 0.9868\n",
            "Epoch 3/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.9955 - val_loss: 0.9815\n",
            "Epoch 4/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.9912 - val_loss: 0.9711\n",
            "Epoch 5/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.9788 - val_loss: 0.9509\n",
            "Epoch 6/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.9591 - val_loss: 0.9280\n",
            "Epoch 7/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.9370 - val_loss: 0.9094\n",
            "Epoch 8/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.9167 - val_loss: 0.8874\n",
            "Epoch 9/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.9013 - val_loss: 0.8686\n",
            "Epoch 10/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.8803 - val_loss: 0.8309\n",
            "Epoch 11/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.8390 - val_loss: 0.7985\n",
            "Epoch 12/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.8107 - val_loss: 0.7902\n",
            "Epoch 13/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.7991 - val_loss: 0.7793\n",
            "Epoch 14/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.7912 - val_loss: 0.7804\n",
            "Epoch 15/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7939 - val_loss: 0.7786\n",
            "Epoch 16/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7929 - val_loss: 0.7694\n",
            "Epoch 17/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.7787 - val_loss: 0.7573\n",
            "Epoch 18/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.7671 - val_loss: 0.7491\n",
            "Epoch 19/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.7610 - val_loss: 0.7480\n",
            "Epoch 20/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.7600 - val_loss: 0.7393\n",
            "Epoch 21/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.7489 - val_loss: 0.7338\n",
            "Epoch 22/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.7448 - val_loss: 0.7252\n",
            "Epoch 23/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.7351 - val_loss: 0.7231\n",
            "Epoch 24/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.7345 - val_loss: 0.7173\n",
            "Epoch 25/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.7276 - val_loss: 0.7123\n",
            "Epoch 26/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.7240 - val_loss: 0.7382\n",
            "Epoch 27/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.7466 - val_loss: 0.7254\n",
            "Epoch 28/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.7320 - val_loss: 0.7213\n",
            "Epoch 29/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.7281 - val_loss: 0.7071\n",
            "Epoch 30/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.7165 - val_loss: 0.7038\n",
            "Epoch 31/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.7097 - val_loss: 0.7066\n",
            "Epoch 32/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7151 - val_loss: 0.7024\n",
            "Epoch 33/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.7073 - val_loss: 0.6907\n",
            "Epoch 34/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7015 - val_loss: 0.6870\n",
            "Epoch 35/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.6981 - val_loss: 0.6838\n",
            "Epoch 36/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.6935 - val_loss: 0.6774\n",
            "Epoch 37/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6884 - val_loss: 0.6759\n",
            "Epoch 38/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.6861 - val_loss: 0.6889\n",
            "Epoch 39/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6974 - val_loss: 0.6806\n",
            "Epoch 40/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6903 - val_loss: 0.6723\n",
            "Epoch 41/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.6838 - val_loss: 0.6742\n",
            "Epoch 42/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.6834 - val_loss: 0.6699\n",
            "Epoch 43/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.6809 - val_loss: 0.6705\n",
            "Epoch 44/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.6804 - val_loss: 0.6722\n",
            "Epoch 45/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.6890 - val_loss: 0.6670\n",
            "Epoch 46/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6795 - val_loss: 0.6687\n",
            "Epoch 47/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6795 - val_loss: 0.6652\n",
            "Epoch 48/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.6783 - val_loss: 0.6644\n",
            "Epoch 49/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.6754 - val_loss: 0.6637\n",
            "Epoch 50/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.6741 - val_loss: 0.6633\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step\n",
            "Mean of Accuracies for Time Domain is:  0.784\n",
            "SD of Accuracies for Frequency Domain is:  0.15344054223053305\n"
          ]
        }
      ]
    }
  ]
}